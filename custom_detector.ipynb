{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCbH2PY1tq0z"
      },
      "source": [
        "### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvnHl_58tq06"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVdkULSUvvwh",
        "outputId": "a3227e85-7dc1-464b-89db-02a3171c8a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constants\n"
      ],
      "metadata": {
        "id": "4dnaMd6Cml8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_annotations_mask_path = \"/content/drive/My Drive/Data for students/yolo_annotations_mask\"  # Путь до файлов в формате YOLO для маскирования/сегментации\n",
        "yolo_annotations_path = \"/content/drive/My Drive/Data for students/yolo_annotations\"            # Путь до файлов в формате YOLO для детекции\n",
        "path_to_folder = \"/content/drive/My Drive/Data for students/img\"                                # Путь к исходным изображениям хлопьев\n",
        "output_folder = \"/content/drive/My Drive/Data for students/processed_img_bbox\"                  # Путь для вывода изображений после разметки сегментации/детекции"
      ],
      "metadata": {
        "id": "2jBYC_VOWwWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rv5lIACtq0_"
      },
      "source": [
        "### Crop image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsrnxDP9tq1C"
      },
      "outputs": [],
      "source": [
        "def crop_image(image, crop_top=0, crop_left=0, crop_right=0, crop_bottom=0):\n",
        "    \"\"\"\n",
        "    Функция для обрезки изображения с указанием процента обрезки по каждому краю.\n",
        "\n",
        "    Параметры:\n",
        "    - image: ndarray\n",
        "        Исходное изображение в формате NumPy массива (например, загруженное с помощью OpenCV).\n",
        "    - crop_top: float, optional (default=0)\n",
        "        Процент обрезки сверху от общей высоты изображения.\n",
        "    - crop_left: float, optional (default=0)\n",
        "        Процент обрезки слева от общей ширины изображения.\n",
        "    - crop_right: float, optional (default=0)\n",
        "        Процент обрезки справа от общей ширины изображения.\n",
        "    - crop_bottom: float, optional (default=0)\n",
        "        Процент обрезки снизу от общей высоты изображения.\n",
        "\n",
        "    Возвращает:\n",
        "    - cropped_image: ndarray\n",
        "        Обрезанное изображение в виде копии исходного массива.\n",
        "    \"\"\"\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    top_px = int(height * crop_top / 100)\n",
        "    left_px = int(width * crop_left / 100)\n",
        "    right_px = int(width * crop_right / 100)\n",
        "    bottom_px = int(height * crop_bottom / 100)\n",
        "\n",
        "    # if top_px + bottom_px >= height:\n",
        "    #     raise ValueError(\"Сумма процентов обрезки сверху и снизу должна быть меньше 100% высоты изображения.\")\n",
        "    # if left_px + right_px >= width:\n",
        "    #     raise ValueError(\"Сумма процентов обрезки слева и справа должна быть меньше 100% ширины изображения.\")\n",
        "\n",
        "    cropped_image = image[top_px:height - bottom_px, left_px:width - right_px]\n",
        "\n",
        "    return cropped_image.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXLYiOjQtq1J"
      },
      "source": [
        "#### Image loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL4voaX0tq1N"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder_path):\n",
        "    \"\"\"\n",
        "    Загружает все изображения из указанной папки и возвращает их в виде словаря.\n",
        "\n",
        "    Параметры:\n",
        "    - folder_path (str): Путь к папке с изображениями.\n",
        "\n",
        "    Возвращает:\n",
        "    - dict: Словарь, где ключи — имена файлов изображений, а значения — загруженные кадры.\n",
        "    \"\"\"\n",
        "    images = {}\n",
        "    # Расширения файлов, которые считаются изображениями\n",
        "    supported_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.gif')\n",
        "\n",
        "    # Проверяем, существует ли папка\n",
        "    if not os.path.isdir(folder_path):\n",
        "        raise ValueError(f\"Папка по пути '{folder_path}' не найдена.\")\n",
        "\n",
        "    # Проходим по всем файлам в папке\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith(supported_extensions):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            # Читаем изображение с помощью OpenCV\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                images[filename] = img\n",
        "            else:\n",
        "                print(f\"Предупреждение: Не удалось загрузить изображение '{filename}'. Оно будет пропущено.\")\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To YOLO format"
      ],
      "metadata": {
        "id": "Z2L7p_xKjEN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools as f\n",
        "\n",
        "def mask_to_yolo_format(image, contours, classes):\n",
        "    \"\"\"\n",
        "    Преобразует контуры объектов изображения в формат аннотаций YOLO.\n",
        "\n",
        "    Параметры:\n",
        "    - image: ndarray\n",
        "        Изображение, к которому применяются контуры, в формате NumPy массива (например, загруженное с помощью OpenCV).\n",
        "        Требуется, чтобы изображение имело форму (height, width, channels).\n",
        "    - contours: list\n",
        "        Список контуров объектов на изображении. Каждый контур — это список точек,\n",
        "        где каждая точка представлена в формате [[x, y]].\n",
        "    - classes: list\n",
        "        Список классов, соответствующих каждому контуру. Каждый элемент — это ID класса (целое число).\n",
        "\n",
        "    Возвращает:\n",
        "    - yolo_annotations: list\n",
        "        Список строк аннотаций в формате YOLO. Каждая строка содержит:\n",
        "        - ID класса,\n",
        "        - координаты всех точек контура, нормализованные в диапазон [0, 1] относительно ширины и высоты изображения.\n",
        "    \"\"\"\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    yolo_annotations = []\n",
        "\n",
        "    for contour, class_id in zip(contours, classes):\n",
        "        xys = [[point[0][0] / width, point[0][1] / height] for point in contour]\n",
        "        to_str = f.reduce(lambda xs, x: xs + x, xys)\n",
        "        annotation = f\"{class_id} \" + \" \".join(map(str, to_str))\n",
        "        yolo_annotations.append(annotation)\n",
        "\n",
        "    return yolo_annotations"
      ],
      "metadata": {
        "id": "_PbH96RKlZCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_yolo_format(image, bboxes, class_ids):\n",
        "    \"\"\"\n",
        "    Преобразует ограничивающие рамки объектов (bounding boxes) в формат аннотаций YOLO.\n",
        "\n",
        "    Параметры:\n",
        "    - image: ndarray\n",
        "        Изображение, к которому применяются bounding boxes, в формате NumPy массива\n",
        "        (например, загруженное с помощью OpenCV). Требуется, чтобы изображение имело форму (height, width, channels).\n",
        "    - bboxes: list\n",
        "        Список ограничивающих рамок объектов. Каждая рамка представлена в формате [x_min, y_min, x_max, y_max],\n",
        "        где:\n",
        "          * x_min, y_min — координаты верхнего левого угла рамки;\n",
        "          * x_max, y_max — координаты нижнего правого угла рамки.\n",
        "    - class_ids: list\n",
        "        Список классов, соответствующих каждому bounding box. Каждый элемент — это ID класса (целое число).\n",
        "\n",
        "    Возвращает:\n",
        "    - yolo_annotations: list\n",
        "        Список строк аннотаций в формате YOLO. Каждая строка содержит:\n",
        "        - ID класса,\n",
        "        - координаты центра рамки (x_center, y_center),\n",
        "        - ширину и высоту рамки (bbox_width, bbox_height),\n",
        "        нормализованные в диапазон [0, 1] относительно ширины и высоты изображения.\n",
        "    \"\"\"\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    yolo_annotations = []\n",
        "\n",
        "    for bbox, class_id in zip(bboxes, class_ids):\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "\n",
        "        # Вычисляем центр и размеры\n",
        "        x_center = (x_min + x_max) / 2.0\n",
        "        y_center = (y_min + y_max) / 2.0\n",
        "        bbox_width = x_max - x_min\n",
        "        bbox_height = y_max - y_min\n",
        "\n",
        "        # Нормализуем значения\n",
        "        x_center /= width\n",
        "        y_center /= height\n",
        "        bbox_width /= width\n",
        "        bbox_height /= height\n",
        "\n",
        "        # Формируем строку в формате YOLO\n",
        "        annotation = f\"{class_id} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\"\n",
        "        yolo_annotations.append(annotation)\n",
        "\n",
        "    return yolo_annotations"
      ],
      "metadata": {
        "id": "oc6Q4D-mpylI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw3AzHlWtq1W"
      },
      "source": [
        "### Find dominant color"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_kmeans_clusters(blue_red_pixels, labels, cluster_centers):\n",
        "    \"\"\"\n",
        "    Строит визуализацию кластеров KMeans для двухмерных данных (синие и красные компоненты).\n",
        "\n",
        "    Параметры:\n",
        "    - blue_red_pixels: ndarray\n",
        "        Двумерный массив пикселей, где каждая строка представляет собой пару значений\n",
        "        (интенсивность синего и красного каналов) в формате [[B, R], ...].\n",
        "    - labels: ndarray\n",
        "        Одномерный массив меток кластеров, присвоенных каждому пикселю алгоритмом KMeans.\n",
        "    - cluster_centers: ndarray\n",
        "        Двумерный массив координат центров кластеров, вычисленных KMeans, в формате [[B, R], ...].\n",
        "\n",
        "    Описание работы:\n",
        "    1. Для каждого кластера определяются точки, принадлежащие этому кластеру.\n",
        "    2. Точки каждого кластера отображаются на диаграмме рассеяния разными цветами.\n",
        "    3. Центры кластеров отображаются черными крестиками (`x`) для визуального обозначения их положения.\n",
        "    4. Диаграмма имеет подписи осей, заголовок, легенду и сетку для улучшения восприятия.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for cluster_id in np.unique(labels):\n",
        "      cluster_points = blue_red_pixels[labels == cluster_id]\n",
        "      plt.scatter(\n",
        "          cluster_points[:, 0], cluster_points[:, 1],\n",
        "          label=f\"Cluster {cluster_id + 1}\",\n",
        "          s=10\n",
        "      )\n",
        "    plt.scatter(\n",
        "        cluster_centers[:, 0], cluster_centers[:, 1],\n",
        "        color='black',\n",
        "        marker='x',\n",
        "        s=200,\n",
        "        label='Cluster Centers'\n",
        "    )\n",
        "\n",
        "    plt.title(\"KMeans Clustering on Blue-Red Pixels\")\n",
        "    plt.xlabel(\"Blue Channel Intensity\")\n",
        "    plt.ylabel(\"Red Channel Intensity\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "C_2LBxq0iwaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def find_dominant_color(image, bbox, n_colors=2):\n",
        "    \"\"\"\n",
        "    Определяет доминирующий цвет в заданной области изображения.\n",
        "\n",
        "    Параметры:\n",
        "    - image: ndarray\n",
        "        Исходное изображение в формате NumPy массива (например, загруженное с помощью OpenCV).\n",
        "    - bbox: tuple (x, y, w, h)\n",
        "        Ограничивающая рамка (bounding box), задающая область интереса:\n",
        "        * x, y — координаты верхнего левого угла рамки;\n",
        "        * w, h — ширина и высота рамки.\n",
        "    - n_colors: int, optional (default=2)\n",
        "        Количество кластеров для метода KMeans (сколько основных цветов будет определено).\n",
        "\n",
        "    Возвращает:\n",
        "    - paint_color: tuple (B, G, R)\n",
        "        Доминирующий цвет в области интереса в формате BGR:\n",
        "        * (255, 0, 0) — если синий цвет преобладает;\n",
        "        * (0, 0, 255) — если красный цвет преобладает.\n",
        "\n",
        "    Описание работы:\n",
        "    1. Из области изображения, заданной `bbox`, выделяется подмассив (область интереса).\n",
        "    2. Удаляются белые пиксели (пиксели с компонентами R, G, B, равными 255), чтобы исключить фон.\n",
        "    3. Выбираются только две цветовые компоненты: синий (B) и красный (R), игнорируя зеленый (G).\n",
        "    4. Используется алгоритм KMeans для кластеризации пикселей по их цветам (синие и красные группы).\n",
        "    5. Считаются доминирующие цвета, и выбирается тот, который преобладает.\n",
        "    6. Возвращается `paint_color`, указывающий доминирующий цвет (синий или красный).\n",
        "    \"\"\"\n",
        "    x, y, w, h = bbox\n",
        "\n",
        "    # Вырезаем область пятна\n",
        "    spot = image[y:y+h, x:x+w]\n",
        "    # Удаление белых пикселей\n",
        "    spot = spot[~((spot[:, :, 0] == 255) & (spot[:, :, 1] == 255) & (spot[:, :, 2] == 255))]\n",
        "\n",
        "    spot = spot.reshape(-1, 3)\n",
        "    spot = spot[:, [0, 2]] # Фичи: blue, red\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_colors, max_iter=1000, random_state=0)\n",
        "    kmeans.fit(spot)\n",
        "\n",
        "    # plot_kmeans_clusters(spot, kmeans.labels_, kmeans.cluster_centers_)\n",
        "\n",
        "    colors = kmeans.cluster_centers_.astype(int)\n",
        "    counts = np.bincount(kmeans.labels_)\n",
        "\n",
        "    sorted_indices = np.argsort(-counts)\n",
        "    sorted_colors = colors[sorted_indices]\n",
        "\n",
        "    dominant_color = tuple(map(int, sorted_colors[0]))\n",
        "\n",
        "    if dominant_color[0] > dominant_color[1]:\n",
        "        paint_color = (255, 0, 0) # blue\n",
        "    else:\n",
        "        paint_color = (0, 0, 255) # red\n",
        "\n",
        "    return paint_color\n"
      ],
      "metadata": {
        "id": "cgzrF1e995MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQCGdj2Ptq1R"
      },
      "source": [
        "### Find counters\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_white_border(image, border_size=10):\n",
        "    \"\"\"\n",
        "    Добавляет белую рамку вокруг изображения.\n",
        "\n",
        "    Параметры:\n",
        "    - image: ndarray\n",
        "        Исходное изображение.\n",
        "    - border_size: int, optional (default=10)\n",
        "        Размер белой рамки в пикселях с каждой стороны.\n",
        "\n",
        "    Возвращает:\n",
        "    - image_with_border: ndarray\n",
        "        Изображение с добавленной белой рамкой.\n",
        "    \"\"\"\n",
        "    white_color = (255, 255, 255)\n",
        "    return cv2.copyMakeBorder(image, border_size, border_size, border_size, border_size, cv2.BORDER_CONSTANT, value=white_color)\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"\n",
        "    Выполняет предварительную обработку изображения для выделения контуров.\n",
        "\n",
        "    Параметры:\n",
        "    - image: ndarray\n",
        "        Изображение в оттенках серого.\n",
        "\n",
        "    Возвращает:\n",
        "    - eroded: ndarray\n",
        "        Обработанное изображение с готовыми для поиска контурами.\n",
        "    \"\"\"\n",
        "    blurred = cv2.GaussianBlur(image, (11, 11), 1.4)\n",
        "    edges = cv2.Canny(blurred, 12, 25)\n",
        "\n",
        "    # Применяем морфологическое закрытие, чтобы заполнить дыры\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
        "    closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # **Расширение** для объединения близких контуров\n",
        "    dilation_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
        "    dilated = cv2.dilate(closed, dilation_kernel, iterations=1)\n",
        "\n",
        "    # **Эрозия** для уточнения контуров после расширения\n",
        "    erosion_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "    eroded = cv2.erode(dilated, erosion_kernel, iterations=1)\n",
        "\n",
        "    return eroded\n",
        "\n",
        "def save_yolo_annotations(yolo_annotations, filename, output_path):\n",
        "    \"\"\"\n",
        "    Сохраняет аннотации YOLO в текстовый файл.\n",
        "\n",
        "    Параметры:\n",
        "    - yolo_annotations: list\n",
        "        Список строк аннотаций в формате YOLO.\n",
        "    - filename: str\n",
        "        Имя файла без расширения.\n",
        "    - output_path: str\n",
        "        Путь к директории, где будет сохранён файл.\n",
        "\n",
        "    Возвращает:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    file_path = f\"{output_path}/{filename}.txt\"\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write('\\n'.join(yolo_annotations))"
      ],
      "metadata": {
        "id": "IsOR_uJuDKGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(image, contours, colors):\n",
        "    \"\"\"\n",
        "    Создает маску, закрашивая контуры заданными цветами.\n",
        "\n",
        "    Параметры:\n",
        "    - image: ndarray\n",
        "        Исходное изображение, определяющее размер маски.\n",
        "    - contours: list\n",
        "        Список контуров, которые необходимо закрасить. Каждый контур представлен массивом координат.\n",
        "    - colors: list\n",
        "        Список цветов для каждого контура. Каждый цвет — это кортеж в формате BGR, например, (255, 0, 0).\n",
        "\n",
        "    Возвращает:\n",
        "    - mask: ndarray\n",
        "        Изображение-маска того же размера, что и `image`, с закрашенными контурами.\n",
        "\n",
        "    Описание работы:\n",
        "    1. Создается пустая белая маска того же размера, что и исходное изображение.\n",
        "    2. Каждый контур из списка `contours` закрашивается соответствующим цветом из `colors`.\n",
        "    3. Для закрашивания используется функция OpenCV `cv2.drawContours` с параметром `thickness=cv2.FILLED`.\n",
        "    \"\"\"\n",
        "    # Создаем пустую маску того же размера, что и изображение\n",
        "    mask = np.zeros(image.shape, dtype=np.uint8) + 255\n",
        "\n",
        "    # Перекрашиваем каждый контур в свой цвет\n",
        "    for contour, color in zip(contours, colors):\n",
        "        cv2.drawContours(mask, [contour], -1, color, thickness=cv2.FILLED)\n",
        "\n",
        "    return mask"
      ],
      "metadata": {
        "id": "o9hJc10lTCOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import imutils\n",
        "\n",
        "def my_find_contours(image, filename, display_steps=False):\n",
        "    \"\"\"\n",
        "    Находит контуры на изображении, определяет доминирующие цвета внутри областей,\n",
        "    формирует маску и аннотации в формате YOLO.\n",
        "\n",
        "    Параметры:\n",
        "    - image: ndarray\n",
        "        Исходное изображение.\n",
        "    - filename: str\n",
        "        Имя файла для сохранения результата.\n",
        "    - display_steps: bool, optional (default=False)\n",
        "        Если True, промежуточные шаги обработки изображения будут визуализированы.\n",
        "\n",
        "    Возвращает:\n",
        "    - image: ndarray\n",
        "        Изображение с обработанными контурами.\n",
        "    \"\"\"\n",
        "    # Добавляем белую рамку\n",
        "    image_with_border = add_white_border(image)\n",
        "\n",
        "    # Конвертируем в оттенки серого\n",
        "    if len(image_with_border.shape) == 3:\n",
        "        gray = cv2.cvtColor(image_with_border, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image_with_border.copy()\n",
        "\n",
        "    if display_steps:\n",
        "        cv2_imshow(gray)\n",
        "\n",
        "    # Обработка изображения\n",
        "    eroded = preprocess_image(gray)\n",
        "    eroded = eroded[10:-10, 10:-10]\n",
        "\n",
        "    if display_steps:\n",
        "        cv2_imshow(eroded)\n",
        "\n",
        "    # Поиск контуров\n",
        "    contours = cv2.findContours(eroded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = imutils.grab_contours(contours)\n",
        "\n",
        "    # Сегментация\n",
        "    # for c in contours:\n",
        "    #     # Вычисление периметра контура\n",
        "    #     p = cv2.arcLength(c, True)\n",
        "    #     # Аппроксимация контура\n",
        "    #     approx = cv2.approxPolyDP(c, 0.02 * p, True)\n",
        "    #     # Отрисовка контуров\n",
        "    #     cv2.drawContours(image, [approx], -1, (0, 255, 0), 1)  # Зеленые контуры (BGR: 0, 255, 0)\n",
        "\n",
        "    # Детекция\n",
        "    bboxes = []  # Для хранения ограничивающих рамок\n",
        "    classes = [] # Для хранения класса для каждой рамки (0 -- синий, 1 -- красный)\n",
        "    colors = []  # Для хранения самих цветов\n",
        "    for c in contours:\n",
        "        x, y, w, h = cv2.boundingRect(c)\n",
        "        dominant_color = find_dominant_color(image, (x, y, w, h))\n",
        "        bboxes.append((x, y, x + w, y + h))\n",
        "        classes.append(0 if dominant_color[0] == 255 else 1)\n",
        "        colors.append(dominant_color)\n",
        "\n",
        "    # Создание маски\n",
        "    # mask = create_mask(image, contours, colors)\n",
        "\n",
        "    # Сохранение аннотаций YOLO\n",
        "    yolo_annotations = mask_to_yolo_format(image, contours, classes)\n",
        "    save_yolo_annotations(yolo_annotations, filename, yolo_annotations_mask_path)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "WApB7kqAFjLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_find_contours_with_bbox(image, filename, display_steps=False):\n",
        "    \"\"\"\n",
        "    Находит контуры на изображении, определяет доминирующие цвета и рисует bounding box для каждого объекта.\n",
        "\n",
        "    Параметры:\n",
        "    - image: ndarray\n",
        "        Исходное изображение.\n",
        "    - filename: str\n",
        "        Имя файла для сохранения результата.\n",
        "    - display_steps: bool, optional (default=False)\n",
        "        Если True, промежуточные шаги обработки изображения будут визуализированы.\n",
        "\n",
        "    Возвращает:\n",
        "    - image: ndarray\n",
        "        Изображение с наложенными bounding box.\n",
        "    \"\"\"\n",
        "    # Добавляем белую рамку\n",
        "    image_with_border = add_white_border(image)\n",
        "\n",
        "    # Конвертируем в оттенки серого\n",
        "    if len(image_with_border.shape) == 3:\n",
        "        gray = cv2.cvtColor(image_with_border, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image_with_border.copy()\n",
        "\n",
        "    if display_steps:\n",
        "        cv2_imshow(gray)\n",
        "\n",
        "    # Обработка изображения\n",
        "    eroded = preprocess_image(gray)\n",
        "    eroded = eroded[10:-10, 10:-10]\n",
        "\n",
        "    if display_steps:\n",
        "        cv2_imshow(eroded)\n",
        "\n",
        "    # Поиск контуров\n",
        "    contours = cv2.findContours(eroded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = imutils.grab_contours(contours)\n",
        "\n",
        "    # Сегментация и генерация bounding box\n",
        "    bboxes = []  # Для хранения ограничивающих рамок\n",
        "    classes = [] # Для хранения класса для каждой рамки (0 -- синий, 1 -- красный)\n",
        "    for c in contours:\n",
        "        x, y, w, h = cv2.boundingRect(c)\n",
        "        dominant_color = find_dominant_color(image, (x, y, w, h))\n",
        "        bboxes.append((x, y, x + w, y + h))\n",
        "        classes.append(0 if dominant_color[0] == 255 else 1)\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), dominant_color, 1)\n",
        "\n",
        "    # Сохранение аннотаций YOLO\n",
        "    yolo_annotations = convert_to_yolo_format(image, bboxes, classes)\n",
        "    save_yolo_annotations(yolo_annotations, filename, yolo_annotations_path)\n",
        "\n",
        "    if display_steps:\n",
        "        cv2_imshow(image)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "hY3wo8k5F2fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR00uJtTtq1d"
      },
      "source": [
        "### Start scr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6NeuJCntq1e"
      },
      "outputs": [],
      "source": [
        "def processing(path_to_folder, crop_top, crop_left, crop_right, crop_bottom, output_folder=\"output\"):\n",
        "    \"\"\"\n",
        "    Выполняет обработку изображений из указанной папки: обрезку, обработку контуров\n",
        "    и сохранение результатов в указанную выходную папку.\n",
        "\n",
        "    Параметры:\n",
        "    - path_to_folder: str\n",
        "        Путь к папке с исходными изображениями.\n",
        "    - crop_top: float\n",
        "        Процент обрезки сверху от общей высоты изображения.\n",
        "    - crop_left: float\n",
        "        Процент обрезки слева от общей ширины изображения.\n",
        "    - crop_right: float\n",
        "        Процент обрезки справа от общей ширины изображения.\n",
        "    - crop_bottom: float\n",
        "        Процент обрезки снизу от общей высоты изображения.\n",
        "    - output_folder: str, optional (default=\"output\")\n",
        "        Путь к папке, куда будут сохранены обработанные изображения.\n",
        "\n",
        "    Возвращает:\n",
        "    - None\n",
        "\n",
        "    Описание работы:\n",
        "    1. Загружает изображения из папки `path_to_folder` с использованием `load_images_from_folder`.\n",
        "    2. Обрезает каждое изображение с помощью `crop_image` на основе заданных процентов обрезки.\n",
        "    3. Применяет одну из функций обработки:\n",
        "        - `my_find_contours` для обработки контуров или создания масок.\n",
        "        - `my_find_contours_with_bbox` для создания bounding box.\n",
        "    4. Сохраняет обработанные изображения в указанную папку `output_folder`.\n",
        "    \"\"\"\n",
        "    images = load_images_from_folder(folder_path=path_to_folder)\n",
        "\n",
        "    for i, (name_file, image) in enumerate(images.items()):\n",
        "        frame = crop_image(image,\n",
        "                            crop_top=crop_top,\n",
        "                            crop_left=crop_left,\n",
        "                            crop_right=crop_right,\n",
        "                            crop_bottom=crop_bottom)\n",
        "        # Обработка изображения\n",
        "        # processed_image = my_find_contours(frame, name_file[:-4], False) # my contours\n",
        "        processed_image = my_find_contours_with_bbox(frame, name_file[:-4], False) # my bbox\n",
        "\n",
        "        # Формируем путь для сохранения файла\n",
        "        output_path = os.path.join(output_folder, f\"{name_file}\")\n",
        "\n",
        "        # Сохраняем обработанное изображение\n",
        "        cv2.imwrite(output_path, processed_image)\n",
        "        # print(f\"Обработанное изображение сохранено: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crop_top = 0     # %\n",
        "crop_left = 0    # %\n",
        "crop_right = 0   # %\n",
        "crop_bottom = 0  # %"
      ],
      "metadata": {
        "id": "6GGmPnvnMdID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processing(path_to_folder=path_to_folder,\n",
        "           crop_top=crop_top,\n",
        "           crop_right=crop_right,\n",
        "           crop_left=crop_left,\n",
        "           crop_bottom=crop_bottom,\n",
        "           output_folder=output_folder)"
      ],
      "metadata": {
        "id": "BbTxPdIlWxx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kflspIUXWziS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pythonProject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sZiqffgFcYU3"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}